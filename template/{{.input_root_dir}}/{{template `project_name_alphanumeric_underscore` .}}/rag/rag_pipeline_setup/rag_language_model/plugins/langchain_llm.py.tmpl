from abc import ABC, abstractmethod
from typing import Any, Dict, Optional, List
from pydantic import PrivateAttr
import os

from langchain_core.language_models import BaseChatModel
from databricks_langchain import ChatDatabricks

from rag_pipeline_setup import constants
from rag_pipeline_setup.flavor_enums import LanguageModelFlavor
from rag_pipeline_setup.rag_language_model.base_language_model import AbstractBaseLLM


class AbstractLangChainLLM(AbstractBaseLLM, ABC):
    """
    Abstract base class for LangChain LLM integrations.

    This class defines a standardized initialization process for language models,
    with abstract methods that concrete subclasses must implement to customize
    the setup process for specific LLM providers.
    """

    _llm: BaseChatModel = PrivateAttr(default=None)

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        try:
            self._pre_setup_steps()
            self._setup_llm_model()
            self._post_setup_steps()
            self._logger.info(f"Successfully initialized Language model: '{self.alias}'")
        except Exception as e:
            self._logger.error(f"Failed to initialize Language model '{self.alias}': {e}")
            raise

    @abstractmethod
    def _pre_setup_steps(self) -> None:
        pass

    @abstractmethod
    def _post_setup_steps(self) -> None:
        pass

    @abstractmethod
    def _setup_llm_model(self) -> None:
        pass


class DatabricksLLM(AbstractLangChainLLM):
    """
    LangChain integration for Databricks language models.

    This class provides a wrapper for Databricks' language models, handling
    authentication via service principal credentials and configuring the
    model with appropriate parameters.
    """

    model_name: str
    temperature: float = 0.0
    n: int = 1
    stop: Optional[List[str]] = None
    max_tokens: Optional[int] = None
    extra_params: Optional[Dict[str, Any]] = None
    stream_usage: bool = False

    _llm: ChatDatabricks = PrivateAttr(default=None)

    def __init__(self, **kwargs):
        super().__init__(**kwargs)

    def _setup_llm_model(self) -> None:
        try:
            self._llm = ChatDatabricks(
                endpoint=self.model_name,
                temperature=self.temperature,
                n=self.n,
                stop=self.stop,
                max_tokens=self.max_tokens,
                extra_params=self.extra_params,
                stream_usage=self.stream_usage
            )
        except Exception as e:
            self._logger.error(f"Failed to initialize language model: '{e}'")
            raise RuntimeError(f"Failed to initialize language model: '{e}'")

    def _pre_setup_steps(self) -> None:
        self._logger.info(f"Checking Databricks authentication using Service Principal for Language Model: '{self.alias}'")
        if not os.environ.get(constants.DATABRICKS_CLIENT_ID, False):
            raise RuntimeError(f"Missing '{constants.DATABRICKS_CLIENT_ID}' in environment variable")
        if not os.environ.get(constants.DATABRICKS_CLIENT_SECRET, False):
            raise RuntimeError(f"Missing '{constants.DATABRICKS_CLIENT_SECRET}' in environment variable")
        if not os.environ.get(constants.DATABRICKS_HOST, False):
            raise RuntimeError(f"Missing '{constants.DATABRICKS_HOST}' in environment variable")

    def _post_setup_steps(self) -> None:
        self._logger.warning(f"No post-setup steps defined for language model '{self.alias}'")
        pass

    @staticmethod
    def llm_flavor() -> str:
        return LanguageModelFlavor.LANGCHAIN_CHAT_DATABRICKS.value
