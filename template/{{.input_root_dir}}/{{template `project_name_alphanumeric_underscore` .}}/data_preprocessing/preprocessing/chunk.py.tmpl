"""
This sample module contains data preprocessing logic to chunk HTML text. 
You should plug in your own data chunking logic in the split_html_on_h2 method below.
"""

from langchain.text_splitter import (
    HTMLHeaderTextSplitter,
    RecursiveCharacterTextSplitter,
)
from transformers import OpenAIGPTTokenizer

# Initialize tokenizer once
tokenizer = OpenAIGPTTokenizer.from_pretrained("openai-gpt")


def get_splitters(max_chunk_size: int, chunk_overlap: int):
    """Initialize splitters with the shared tokenizer.

    :param max_chunk_size: The maximum size of a chunk.
    :param chunk_overlap: Target overlap between chunks.
    Overlapping chunks helps to mitigate loss of information when context is divided between chunks.
    :return: A tuple of text splitter and html text splitter
    """
    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(
        tokenizer, chunk_size=max_chunk_size, chunk_overlap=chunk_overlap
    )
    html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=[("h2", "header2")])
    return text_splitter, html_splitter


def split_html_on_h2(
    html: str, chunk_overlap: int, min_chunk_size: int, max_chunk_size: int
):
    """Parse and split HTML content into chunks.

    Split on H2, but merge small h2 chunks together to avoid too small.
    It uses HTMLHeaderTextSplitter to parse the HTML content and
    RecursiveCharacterTextSplitter to split the text into chunks

    TODO: Update and adapt the sample code for your use case

    :param html: HTML content
    :param chunk_overlap: Target overlap between chunks.
    Overlapping chunks helps to mitigate loss of information when context is divided between chunks.
    :param min_chunk_size: The minimum size of a chunk.
    :param max_chunk_size: The maximum size of a chunk.
    :return: List of chunked text for input HTML content
    """
    if not html:
        return []

    # Get splitters
    text_splitter, html_splitter = get_splitters(max_chunk_size, chunk_overlap)

    h2_chunks = html_splitter.split_text(html)
    chunks = []
    previous_chunk = ""

    # Merge chunks together to add text before h2 and avoid too small docs.
    for c in h2_chunks:
        # Concat the h2 (note: we could remove the previous chunk to avoid duplicate h2)
        content = c.metadata.get("header2", "") + "\n" + c.page_content
        if len(tokenizer.encode(previous_chunk + content)) <= max_chunk_size / 2:
            previous_chunk += content + "\n"
        else:
            chunks.extend(text_splitter.split_text(previous_chunk.strip()))
            previous_chunk = content + "\n"

    if previous_chunk:
        chunks.extend(text_splitter.split_text(previous_chunk.strip()))

    # Discard chunks smaller than min_chunk_size
    return [c for c in chunks if len(tokenizer.encode(c)) > min_chunk_size]
